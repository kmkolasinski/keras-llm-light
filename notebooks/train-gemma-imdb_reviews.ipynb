{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_datasets\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 18:24:46.991232: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-04 18:24:47.021265: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 18:24:47.605050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.16.1', '3.3.3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [-1, 0, -1, 0, -1, 0, -1, 0, -1, 1000.0]\n",
    "np.percentile(values, 10, method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "# kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_llm_light import gemma_2b\n",
    "\n",
    "LORA_RANK = 4\n",
    "LORA_APLHA = 32.0\n",
    "MAX_SEQ_LENGTH = 512\n",
    "\n",
    "\n",
    "gemma_llm = gemma_2b.build_gemma_llm_cpu(\n",
    "    lora_rank=LORA_RANK,\n",
    "    lora_alpha=LORA_APLHA,\n",
    ")\n",
    "gemma_llm.preprocessor.sequence_length = MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "preprocessing_op, token_embedding_layer = gemma_2b.build_gemma_preprocessing_fn(gemma_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_op.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_block = gemma_2b.build_gemma_decoder_block(\n",
    "    gemma_llm=gemma_llm,\n",
    "    lora_rank=LORA_RANK,\n",
    "    lora_alpha=LORA_APLHA,\n",
    ")\n",
    "transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing_op = gemma_2b.build_gemma_postprocessing_fn(gemma_llm)\n",
    "postprocessing_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gemma_2b.build_block_wise_gemma(\n",
    "    gemma_llm=gemma_llm,\n",
    "    token_embeddings=token_embedding_layer,\n",
    "    preprocessing_fn=preprocessing_op,\n",
    "    transformer_block=transformer_block,\n",
    "    postprocessing_fn=postprocessing_op,\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.block_model.print_weights_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(document):\n",
    "    problem = document['Problem']\n",
    "    options = document['options']\n",
    "    correct_option = document['correct'] + \" ) \" + document['correct_option']\n",
    "    text = problem + tf.constant(\"\\nOptions: \") + options + \"\\nAnswer: \" + correct_option\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\"imdb_reviews\", split=\"train\")\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_ds = (\n",
    "    ds.map(prepare_text)\n",
    "    .repeat(-1)\n",
    "    .shuffle(2000)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_processed = train_ds.map(\n",
    "    gemma_llm.preprocessor, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds_processed_iter = iter(train_ds_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_ds:\n",
    "    break\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = \"\\nAnswer: \"\n",
    "parts = sample[0].numpy().decode(\"utf-8\").split(split_key)\n",
    "query = parts[0] + split_key\n",
    "print(query)\n",
    "print(parts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = model.generate(\"Is is Żywiec Jasne or JAsne Pelne?\", max_length=128)\n",
    "print(response_text.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_text.numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i, documents in tqdm(enumerate(train_ds_processed_iter)):\n",
    "    break\n",
    "\n",
    "features, labels, sample_weight = documents\n",
    "token_id_input = features[\"token_ids\"]\n",
    "padding_mask = features[\"padding_mask\"]\n",
    "padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, _ = model.forward(token_id_input, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_llm_light import blocks_ops\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model_loss_op = blocks_ops.BockWiseSoftmaxLoss(\n",
    "    model.token_embeddings.weights[0].value,\n",
    "    postprocessing_op=model.postprocessing_fn,\n",
    "    blocks_weights=model.block_model.blocks_weights,\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "outputs, _ = model.forward(token_id_input, padding_mask)\n",
    "\n",
    "loss, accuracy_value, initial_gradients = model_loss_op.train_loss_step(\n",
    "    outputs, labels, sample_weight, num_splits=2\n",
    ")\n",
    "vars_gradients = model.backward(padding_mask, initial_gradients)\n",
    "\n",
    "\n",
    "model_loss_op.apply_gradients(list(chain.from_iterable(vars_gradients)))\n",
    "loss, accuracy_value, initial_gradients.shape, len(vars_gradients), len(vars_gradients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model_loss_op.fit(model, train_ds_processed, epochs=1, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.plot(metrics_df[\"loss\"], label=\"loss\")\n",
    "plt.subplot(122) \n",
    "plt.plot(metrics_df[\"accuracy\"], label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_ds:\n",
    "    break\n",
    "\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_key = \"\\nAnswer: \"\n",
    "parts = sample[0].numpy().decode(\"utf-8\").split(split_key)\n",
    "query = parts[0] + split_key\n",
    "print(query)\n",
    "print(parts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = model.generate(\"Is is Żywiec Jasne or JAsne Pelne?\", max_length=128)\n",
    "print(response_text.numpy().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
